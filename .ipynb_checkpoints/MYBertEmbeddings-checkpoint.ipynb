{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb5047f4",
   "metadata": {},
   "source": [
    "## Getting clinical word embeddings from BERT models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdbebd8",
   "metadata": {},
   "source": [
    "#### Clinical Bert\n",
    "https://huggingface.co/emilyalsentzer/Bio_ClinicalBERT\n",
    "#### Non-clinical BERT  - for extracting word embeddings\n",
    "https://colab.research.google.com/drive/1yFphU6PW9Uo6lmDly_ud9a6c4RCYlwdX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a019bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch_pretrained_bert\n",
      "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
      "\u001b[K     |████████████████████████████████| 123 kB 471 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting boto3\n",
      "  Downloading boto3-1.21.4-py3-none-any.whl (132 kB)\n",
      "\u001b[K     |████████████████████████████████| 132 kB 969 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /anaconda3/lib/python3.7/site-packages (from pytorch_pretrained_bert) (1.21.2)\n",
      "Requirement already satisfied: tqdm in /anaconda3/lib/python3.7/site-packages (from pytorch_pretrained_bert) (4.62.2)\n",
      "Requirement already satisfied: torch>=0.4.1 in /anaconda3/lib/python3.7/site-packages (from pytorch_pretrained_bert) (1.7.0)\n",
      "Requirement already satisfied: regex in /anaconda3/lib/python3.7/site-packages (from pytorch_pretrained_bert) (2021.8.3)\n",
      "Requirement already satisfied: requests in /anaconda3/lib/python3.7/site-packages (from pytorch_pretrained_bert) (2.26.0)\n",
      "Requirement already satisfied: future in /anaconda3/lib/python3.7/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (0.18.2)\n",
      "Requirement already satisfied: typing_extensions in /anaconda3/lib/python3.7/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.10.0.2)\n",
      "Requirement already satisfied: dataclasses in /anaconda3/lib/python3.7/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (0.6)\n",
      "Collecting botocore<1.25.0,>=1.24.4\n",
      "  Downloading botocore-1.24.5-py3-none-any.whl (8.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.5 MB 4.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting s3transfer<0.6.0,>=0.5.0\n",
      "  Downloading s3transfer-0.5.1-py3-none-any.whl (79 kB)\n",
      "\u001b[K     |████████████████████████████████| 79 kB 4.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /anaconda3/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.4->boto3->pytorch_pretrained_bert) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /anaconda3/lib/python3.7/site-packages (from botocore<1.25.0,>=1.24.4->boto3->pytorch_pretrained_bert) (1.26.7)\n",
      "Requirement already satisfied: six>=1.5 in /anaconda3/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.4->boto3->pytorch_pretrained_bert) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /anaconda3/lib/python3.7/site-packages (from requests->pytorch_pretrained_bert) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /anaconda3/lib/python3.7/site-packages (from requests->pytorch_pretrained_bert) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda3/lib/python3.7/site-packages (from requests->pytorch_pretrained_bert) (2021.10.8)\n",
      "Installing collected packages: jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n",
      "Successfully installed boto3-1.21.4 botocore-1.24.5 jmespath-0.10.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.5.1\n"
     ]
    }
   ],
   "source": [
    "#!pip install transformers\n",
    "!pip install pytorch_pretrained_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46cd7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import logging\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d48225c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from pytorch_pretrained_bert import WEIGHTS_NAME, CONFIG_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cf9208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True, do_basic_tokenize=True)\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c4b5050",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Loading Clinical Bert\n",
    "model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\", output_hidden_states=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "39f69e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert import WEIGHTS_NAME, CONFIG_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b0e3102e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/Users/radix/MachineLearning/MLNLP/clinicalBERT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2f65ca35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we have a distributed model, save only the encapsulated model\n",
    "# (it was wrapped in PyTorch DistributedDataParallel or DataParallel)\n",
    "model_to_save = model.module if hasattr(model, 'module') else model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "16924a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model_file = os.path.join(output_dir, WEIGHTS_NAME)\n",
    "output_config_file = os.path.join(output_dir, CONFIG_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f87c6fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/radix/MachineLearning/MLNLP/clinicalBERT/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "print(output_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "acaedfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_to_save.state_dict(), output_model_file)\n",
    "model_to_save.config.to_json_file(output_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "31aa634d",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = model_to_save.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36d6a46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b06e395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a881fd95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a298803",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375ef9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ['This is a 46-year-old female with a history of events concerning for seizures.',\n",
    "        'The patient has a history of epilepsy and has also had non-epileptic events in the past.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f008e80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d821bb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize text and add special tokens needed for Bert Model\n",
    "tokenized_text = tokenizer.tokenize(text, add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b18823",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff1fbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62eb9a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dict = tokenizer(text[0], text[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296a8ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_ids = encoded_dict['token_type_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0038d707",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = tokenizer.decode(encoded_dict['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490428df",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c9d7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58202041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get indices for tokens\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bac5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for tup in zip(tokenized_text, indexed_tokens):\n",
    "#    print('{:<12} {:>6,}'.format(tup[0], tup[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcb89aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensor = torch.tensor([segment_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174970fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0421b987",
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d1cf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with torch.no_grad():\n",
    "#    outputs = model(tokens_tensor)\n",
    "#hidden_states = outputs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20eed98",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(tokens_tensor, segments_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2709ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model will return a different number of objects based on \n",
    "    # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
    "    # becase we set `output_hidden_states = True`, the third item will be the \n",
    "    # hidden states from all layers. See the documentation for more details:\n",
    "    # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "\n",
    "hidden_states = outputs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc14c6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of layers:\", len(hidden_states))\n",
    "layer_i = 0\n",
    "print(\"Number of batches (sentences)\", len(hidden_states[layer_i]))\n",
    "batch_i = 0\n",
    "print(\"Number of tokens\", len(hidden_states[layer_i][batch_i]))\n",
    "token_i = 0\n",
    "print(\"Number of hidden units\", len(hidden_states[layer_i][batch_i][token_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50af091c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# current dimensions\n",
    "# layers, batches, tokens, features\n",
    "# Desired dimensions\n",
    "# tokens, layers, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fd35a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"type of hidden state: \", type(hidden_states))\n",
    "print(\"Shape of layer:\", hidden_states[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ef2c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack layers\n",
    "token_embeddings = torch.stack(hidden_states, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205ed662",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d5f573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove batches dimension\n",
    "token_embeddings = token_embeddings.squeeze(dim=1)\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16656eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch token, layer dimensions\n",
    "token_embeddings = token_embeddings.permute([1,0,2])\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641dcf26",
   "metadata": {},
   "source": [
    "### Word vectors: Contatenate and sum layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a0a1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_vecs_cat = []\n",
    "for token in token_embeddings:\n",
    "    # token is a 12 x 768 tensor. Concatenate last 4 dimensions for 0th dimension\n",
    "    # Each layer has 768 values so with concatenation of 4 dimensions each layer has 3072 (4x768) values\n",
    "    cat_vec = torch.cat((token[-4], token[-3], token[-2], token[-1]), dim=0)\n",
    "    token_vecs_cat.append(cat_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf66944",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Concatenated token vectors %d x %d' % (len(token_vecs_cat), len(token_vecs_cat[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c6658a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summing of last 4 layers for each token\n",
    "token_vecs_sum = []\n",
    "for token in token_embeddings:\n",
    "    sum_vec = torch.sum(token[-4:], dim=0)\n",
    "    token_vecs_sum.append(sum_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193d8756",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sum Token vectors %d x %d\", (len(token_vecs_sum), len(token_vecs_sum[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e63696a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, str in enumerate(tokenized_text):\n",
    "    print(i, str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81456b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectors for words 'past' and 'history'\n",
    "# 'past' index = 42\n",
    "# 'history' index = 25\n",
    "\n",
    "a = token_vecs_sum[42]\n",
    "b = token_vecs_sum[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e992e73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d92a6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "1-cosine(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8117d5b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d73c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = [0.9, 0.8]\n",
    "d = [0.9, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c71c17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "1- cosine(c,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3876e023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last hidden state as word embeddings\n",
    "last_hidden_state = outputs[0]\n",
    "word_embed_1 = last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d66cd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum of hidden states\n",
    "word_embed_sum = torch.stack(hidden_states).sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb57c12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum of last 4\n",
    "word_embed_sum_last4 = torch.stack(hidden_states[-4:]).sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d8d032",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
